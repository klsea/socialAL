{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SocialAL Model\n",
    "# Fit model to data - one subject\n",
    "KLS 9.19.19  \n",
    "Project info: https://osf.io/b48n2/\n",
    "\n",
    "Model modified from :\n",
    "Fareri, D. S., Chang, L. J., & Delgado, M. R. (2012). Effects of direct social experience on trust decisions and neural reward circuitry. Frontiers in Neuroscience, 6, 1â€“17. https://doi.org/10.3389/fnins.2012.00148"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.3 (default, Mar 27 2019, 16:54:48) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_value(Prob, EV, choice, response):\n",
    "    invest = [0,3,6,9]\n",
    "    retain = [9-x for x in invest] #print (\"Retain list is: \", retain)\n",
    "    shared = [2*x for x in invest] #print (\"Shared list is: \", shared)\n",
    "    EV[choice-1] = retain[choice-1] + Prob*shared[choice-1]\n",
    "    return EV\n",
    "\n",
    "def update_prob(recip, Prob, a_gain, a_loss):\n",
    "    gain = max(recip - Prob, 0)\n",
    "    loss = min(recip - Prob, 0)\n",
    "    Prob = Prob + a_gain * gain + a_loss * loss\n",
    "    return Prob\n",
    "\n",
    "def get_action_selection_prob(beta, EV, choice):\n",
    "    numerator = np.exp(beta*EV[choice-1])\n",
    "    denominator = np.sum([np.exp(beta*x) for x in EV])\n",
    "    actionProb = numerator/denominator\n",
    "    return actionProb\n",
    "\n",
    "def get_action_selection_probs(beta, EV):\n",
    "    actionProbs = [get_action_selection_prob(beta, EV, x) for x in range(1,5)]\n",
    "    return actionProbs\n",
    "\n",
    "def get_likelihood_action(params, data):\n",
    "    a_gain = params[0]\n",
    "    a_loss = params[1]\n",
    "    beta = params[2]\n",
    "    \n",
    "    # initialize variables\n",
    "    prob = [0.5, 0.5, 0.5]\n",
    "    ev = [[9,9,9,9],[9,9,9,9],[9,9,9,9]]\n",
    "    \n",
    "    totalLLH = 0 \n",
    "    for trial in range(0, len(data)):\n",
    "        trustee = data['Stim_Sequence'][trial] # get trustee type\n",
    "        choice = data['Choice'][trial] # get choice made by participant\n",
    "        response = data['Trustee_Response'][trial] # get response from trustee\n",
    "        \n",
    "        # compute the probability of selecting each option for that trustee\n",
    "        probs = get_action_selection_probs(beta, ev[trustee]) #print (probs)\n",
    "        \n",
    "        # use the probability of the selection (choice-probability) to update log likelihood\n",
    "        cprob = probs[choice-1]#print(cprob, isinstance(cprob, float))\n",
    "        \n",
    "        #add to cumulative log likelihood\n",
    "        if cprob == 0.0:\n",
    "            totalLLH = math.inf # if the choice prob is 0.0, set the totalLLH to inf\n",
    "        else:\n",
    "            totalLLH += -(math.log(cprob))\n",
    "        \n",
    "        # update prob and value\n",
    "        if choice != 1:\n",
    "            prob[trustee] = update_prob(response, prob[trustee], a_gain, a_loss)\n",
    "        ev[trustee] = update_value(prob[trustee], ev[trustee], choice, response)\n",
    "        \n",
    "    return totalLLH\n",
    "\n",
    "def model_fit_once(data):\n",
    "        # initialize free parameters with randomly chosen numbers\n",
    "        a_gain=random.uniform(0, 1)\n",
    "        a_loss=random.uniform(0, 1)\n",
    "        beta=random.uniform(0, 1)\n",
    "        params = [a_gain, a_loss, beta]\n",
    "        \n",
    "        results = minimize(get_likelihood_action, \n",
    "                           params, args =(data), method='BFGS', options = {'maxiter': 10000, 'disp': False})\n",
    "        return results\n",
    "\n",
    "def model_fit(data):\n",
    "    \n",
    "    tries = 10 #  number of tries to find the best-fit parameter\n",
    "    lowestLLH = math.inf \n",
    "    bestFit = 'NA'\n",
    "    \n",
    "    for i in range(tries):\n",
    "        \n",
    "        # initialize free parameters with randomly chosen numbers\n",
    "        a_gain=random.uniform(0, 1)\n",
    "        a_loss=random.uniform(0, 1)\n",
    "        beta=random.uniform(0, 1)\n",
    "        params = [a_gain, a_loss, beta]\n",
    "\n",
    "        # trying different solvers in the minimize call...\n",
    "        results = minimize(get_likelihood_action, \n",
    "                           params, args =(data), method='Nelder-Mead', options = {'maxiter': 10000, 'disp': False})\n",
    "        #results = minimize(get_likelihood_action, \n",
    "                           #params, args =(data), method='BFGS', options = {'maxiter': 10000, 'disp': False})\n",
    "        if (lowestLLH > results['fun'] and results['success']== True):\n",
    "            lowestLLH = results['fun']\n",
    "            bestFit = results\n",
    "            \n",
    "    return bestFit\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir('../data/modeling') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv('../data/modeling/sub-1004.csv')\n",
    "#dt = pd.read_csv('../data/modeling/sub-2013.csv') #- try getting this sub to work\n",
    "# recode trial type into numbers for model\n",
    "def stims(trial_type):\n",
    "    if trial_type == \"Trustworthy\":\n",
    "        return 0\n",
    "    elif trial_type == \"Neutral\":\n",
    "        return 1\n",
    "    elif trial_type == \"Untrustworthy\":\n",
    "        return 2\n",
    "dt['Stim_Sequence'] = dt['trial_type'].apply(stims)\n",
    "# rename response_key to choice\n",
    "def choices(response_key):\n",
    "    if response_key == 'None':\n",
    "        return 0 \n",
    "    else:\n",
    "        return response_key  \n",
    "dt['Choice'] = dt['response_key'].apply(choices)\n",
    "dt['Choice'] = pd.to_numeric(dt['Choice'])\n",
    "# calculte the trustee response\n",
    "def resp(trial_earnings):\n",
    "    if trial_earnings >= 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "dt['Trustee_Response'] = dt['trial_earnings'].apply(resp)\n",
    "data = dt[['Stim_Sequence','Choice', 'Trustee_Response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kls190004/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[0.22887264, 0.19404029, 0.49475929],\n",
       "       [0.2289169 , 0.1940401 , 0.49469912],\n",
       "       [0.22888695, 0.19405777, 0.49469431],\n",
       "       [0.22890083, 0.19409121, 0.49471407]]), array([49.30453955, 49.30453958, 49.30453959, 49.30453962]))\n",
       "           fun: 49.304539545110394\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 135\n",
       "           nit: 75\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([0.22887264, 0.19404029, 0.49475929])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = model_fit(data)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 49.304539532022126\n",
       " hess_inv: array([[ 0.02478635,  0.0105868 , -0.02022591],\n",
       "       [ 0.0105868 ,  0.01357454, -0.00847538],\n",
       "       [-0.02022591, -0.00847538,  0.03017287]])\n",
       "      jac: array([-4.76837158e-07,  1.90734863e-06,  1.43051147e-06])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 125\n",
       "      nit: 19\n",
       "     njev: 25\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.22888463, 0.19404725, 0.49473309])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fit_once(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
