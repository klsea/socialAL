{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SocialAL Model\n",
    "\n",
    "### Fit single alpha with decay model to data - multiple subjects\n",
    "\n",
    "KLS 3.3.22\n",
    "Project info: https://osf.io/b48n2/\n",
    "\n",
    "Model modified from : Fareri, D. S., Chang, L. J., & Delgado, M. R. (2012). Effects of direct social experience on trust decisions and neural reward circuitry. Frontiers in Neuroscience, 6, 1â€“17. https://doi.org/10.3389/fnins.2012.00148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.0 (v3.11.0:deaf509e8f, Oct 24 2022, 14:43:23) [Clang 13.0.0 (clang-1300.0.29.30)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import os\n",
    "from decimal import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_value(Prob):\n",
    "    invest = [0,3,6,9]\n",
    "    retain = [9-x for x in invest] #print (\"Retain list is: \", retain)\n",
    "    shared = [2*x for x in invest] #print (\"Shared list is: \", shared)\n",
    "    EV = [(retain[x] + Prob*shared[x]) for x in range(0,4)]\n",
    "    return EV\n",
    "\n",
    "def update_prob(recip, Prob, alpha):\n",
    "    Prob = Prob + alpha*(recip-Prob)\n",
    "    return Prob\n",
    "\n",
    "def get_action_selection_prob(beta, EV, choice):\n",
    "    actionProb = Decimal(np.exp(beta*EV[choice-1])/np.sum([np.exp(beta*x) for x in EV]))\n",
    "    return actionProb\n",
    "\n",
    "def get_action_selection_probs(beta, EV):\n",
    "    actionProbs = [get_action_selection_prob(beta, EV, x) for x in range(1,5)]\n",
    "    return actionProbs\n",
    "\n",
    "def get_likelihood_action(params, data):\n",
    "    alpha = params[0]\n",
    "    beta = params[1]\n",
    "    decay = params[2]\n",
    "    \n",
    "    # initialize variables\n",
    "    prob = [0.5, 0.5, 0.5]\n",
    "    ev = [[9,9,9,9],[9,9,9,9],[9,9,9,9]]\n",
    "    \n",
    "    totalLLH = 0 \n",
    "    for trial in range(0, len(data)):\n",
    "        trustee = data['Stim_Sequence'][trial] # get trustee type\n",
    "        choice = data['Choice'][trial] # get choice made by participant\n",
    "        response = data['Trustee_Response'][trial] # get response from trustee\n",
    "        \n",
    "        # compute the probability of selecting each option for that trustee\n",
    "        probs = get_action_selection_probs(beta, ev[trustee])\n",
    "        \n",
    "        # use the probability of the selection (choice-probability) to update log likelihood\n",
    "        if choice != 0:\n",
    "            cprob = probs[choice-1] #print(cprob, isinstance(cprob, float))\n",
    "            #print(cprob)\n",
    "\n",
    "            #add to cumulative log likelihood\n",
    "            totalLLH += -(math.log(cprob))\n",
    "        \n",
    "            # update prob and value\n",
    "            if choice != 1:\n",
    "                prob[trustee] = update_prob(response, prob[trustee], alpha)\n",
    "            ev[trustee] = update_value(prob[trustee])\n",
    "            \n",
    "        # decay prob and value for other possible trustees \n",
    "        options = [0, 1, 2]\n",
    "        if choice == 2 or choice == 3 or choice == 4:\n",
    "            options.pop(trustee)\n",
    "        for x in options:\n",
    "            prob[x] = prob[x] + decay * (0.5 - prob[x])\n",
    "            ev[x] =  update_value(prob[x])       \n",
    "    return totalLLH\n",
    "\n",
    "def model_fit_once(data):\n",
    "        # initialize free parameters with randomly chosen numbers\n",
    "        alpha=random.uniform(0, 1)\n",
    "        beta=random.uniform(0, 1)\n",
    "        decay=random.uniform(0,1)\n",
    "        params = [alpha, beta, decay]\n",
    "        \n",
    "        #results = minimize(get_likelihood_action, \n",
    "                           #params, args =(data), method='BFGS', options = {'maxiter': 10000, 'disp': False})\n",
    "        results = minimize(get_likelihood_action, \n",
    "                       params, args =(data), bounds = [(0, 1), (1e-10, 100), (0, 1)], \n",
    "                       options = {'maxiter': 10000, 'disp': False})\n",
    "        return results\n",
    "\n",
    "def model_fit(data):\n",
    "    \n",
    "    tries = 100 #  number of tries to find the best-fit parameter\n",
    "    lowestLLH = math.inf \n",
    "    bestFit = 'NA'\n",
    "    \n",
    "    for i in range(tries):\n",
    "        \n",
    "        # initialize free parameters with randomly chosen numbers\n",
    "        alpha=random.uniform(0, 1)\n",
    "        beta=random.uniform(0, 1)\n",
    "        decay=random.uniform(0,1)\n",
    "        params = [alpha, beta, decay]\n",
    "\n",
    "        # trying different solvers in the minimize call...\n",
    "        results = minimize(get_likelihood_action, \n",
    "                           params, args =(data), bounds = [(0, 1), (1e-10, 20), (0, 1)], \n",
    "                           options = {'maxiter': 10000, 'disp': False})\n",
    "        if (lowestLLH > results['fun'] and results['success']== True):\n",
    "            lowestLLH = results['fun']\n",
    "            bestFit = results\n",
    "            \n",
    "    return bestFit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('../../data/modeling/missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sub-2038.csv', 'sub-2039.csv', 'sub-2026.csv', 'sub-2027.csv', 'sub-2033.csv', 'sub-2025.csv', 'sub-2031.csv', 'sub-2030.csv', 'sub-2024.csv', 'sub-2034.csv', 'sub-2021.csv', 'sub-2037.csv', 'sub-2023.csv', 'sub-2022.csv', 'sub-2036.csv']\n"
     ]
    }
   ],
   "source": [
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean(file):\n",
    "    path = os.path.join('../../data/modeling', file)\n",
    "    dt = pd.read_csv(path)\n",
    "    # recode trial type into numbers for model\n",
    "    def stims(trial_type):\n",
    "        if trial_type == \"Trustworthy\":\n",
    "            return 0\n",
    "        elif trial_type == \"Neutral\":\n",
    "            return 1\n",
    "        elif trial_type == \"Untrustworthy\":\n",
    "            return 2\n",
    "    dt['Stim_Sequence'] = dt['trial_type'].apply(stims)\n",
    "    # rename response_key to choice\n",
    "    def choices(response_key):\n",
    "        if response_key == 'None':\n",
    "            return 0 \n",
    "        else:\n",
    "            return response_key  \n",
    "    dt['Choice'] = dt['response_key'].apply(choices)\n",
    "    dt['Choice'] = pd.to_numeric(dt['Choice'])\n",
    "    # calculte the trustee response\n",
    "    def resp(trial_earnings):\n",
    "        if trial_earnings >= 12:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    dt['Trustee_Response'] = dt['trial_earnings'].apply(resp)\n",
    "    data = dt[['Stim_Sequence','Choice', 'Trustee_Response']]\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context(prec=28, rounding=ROUND_HALF_EVEN, Emin=-999999, Emax=999999, capitals=1, clamp=0, flags=[], traps=[InvalidOperation, DivisionByZero, Overflow])\n"
     ]
    }
   ],
   "source": [
    "print(getcontext())\n",
    "params = [model_fit(load_and_clean(file)) for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[      fun: 61.42483725154438\n",
       "  hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "       jac: array([ 2.74269496e-04, -1.35003109e-04, -6.75458974e-01])\n",
       "   message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "      nfev: 312\n",
       "       nit: 55\n",
       "      njev: 78\n",
       "    status: 0\n",
       "   success: True\n",
       "         x: array([6.00213871e-03, 2.00000000e+01, 1.00000000e+00]),\n",
       "       fun: 34.35241933110275\n",
       "  hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "       jac: array([0.00000000e+00, 7.10542732e-07, 2.84217094e-06])\n",
       "   message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "      nfev: 68\n",
       "       nit: 13\n",
       "      njev: 17\n",
       "    status: 0\n",
       "   success: True\n",
       "         x: array([0.83014351, 0.53184832, 0.02098698]),\n",
       "       fun: 58.096880230264\n",
       "  hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "       jac: array([ 2.45847787e-04, -3.62376765e-04, -6.39488459e-06])\n",
       "   message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "      nfev: 304\n",
       "       nit: 57\n",
       "      njev: 76\n",
       "    status: 0\n",
       "   success: True\n",
       "         x: array([9.39193031e-03, 2.00000000e+01, 5.32974457e-01]),\n",
       "       fun: 47.87758945397571\n",
       "  hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "       jac: array([9.23705557e-06, 4.97379913e-06, 8.80182327e+00])\n",
       "   message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "      nfev: 68\n",
       "       nit: 14\n",
       "      njev: 17\n",
       "    status: 0\n",
       "   success: True\n",
       "         x: array([0.12770141, 0.54936011, 0.        ]),\n",
       "       fun: 59.950592639104784\n",
       "  hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "       jac: array([-1.34372726e+00,  1.42108547e-06, -1.06483923e+00])\n",
       "   message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "      nfev: 40\n",
       "       nit: 7\n",
       "      njev: 10\n",
       "    status: 0\n",
       "   success: True\n",
       "         x: array([1.        , 0.11831545, 1.        ]),\n",
       "       fun: 50.730065357748344\n",
       "  hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "       jac: array([ 1.20941479e-02, -1.08002487e-04,  2.30046126e+01])\n",
       "   message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "      nfev: 524\n",
       "       nit: 94\n",
       "      njev: 131\n",
       "    status: 0\n",
       "   success: True\n",
       "         x: array([2.47674978e-03, 2.00000000e+01, 0.00000000e+00]),\n",
       "       fun: 60.99695188927512\n",
       "  hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "       jac: array([ 0.,  0., -0.])\n",
       "   message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "      nfev: 8\n",
       "       nit: 1\n",
       "      njev: 2\n",
       "    status: 0\n",
       "   success: True\n",
       "         x: array([0.e+00, 1.e-10, 1.e+00]),\n",
       "       fun: 58.22436316703534\n",
       "  hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "       jac: array([ 0.,  0., -0.])\n",
       "   message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "      nfev: 8\n",
       "       nit: 1\n",
       "      njev: 2\n",
       "    status: 0\n",
       "   success: True\n",
       "         x: array([0.e+00, 1.e-10, 1.e+00]),\n",
       "       fun: 43.060879982905504\n",
       "  hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "       jac: array([0.00000000e+00, 7.10542736e-07, 1.65659912e+01])\n",
       "   message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "      nfev: 72\n",
       "       nit: 13\n",
       "      njev: 18\n",
       "    status: 0\n",
       "   success: True\n",
       "         x: array([0.46395398, 0.42729294, 0.        ]),\n",
       "       fun: 53.163114682434596\n",
       "  hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "       jac: array([ 3.23346683e-02, -6.03961275e-04,  3.79430254e+01])\n",
       "   message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "      nfev: 328\n",
       "       nit: 52\n",
       "      njev: 82\n",
       "    status: 0\n",
       "   success: True\n",
       "         x: array([1.48266697e-03, 2.00000000e+01, 0.00000000e+00]),\n",
       "       fun: 54.49333181197538\n",
       "  hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "       jac: array([1.42108546e-06, 0.00000000e+00, 1.89245974e+01])\n",
       "   message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "      nfev: 60\n",
       "       nit: 11\n",
       "      njev: 15\n",
       "    status: 0\n",
       "   success: True\n",
       "         x: array([0.93523235, 0.18688861, 0.        ]),\n",
       "       fun: 49.83861397117636\n",
       "  hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "       jac: array([-2.51713813e+00, -7.10542736e-07,  2.84217094e-06])\n",
       "   message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "      nfev: 72\n",
       "       nit: 11\n",
       "      njev: 18\n",
       "    status: 0\n",
       "   success: True\n",
       "         x: array([1.        , 0.26746867, 0.07069158]),\n",
       "       fun: 34.813597189916585\n",
       "  hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "       jac: array([0.00000000e+00, 1.42108546e-06, 3.18910693e+00])\n",
       "   message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "      nfev: 152\n",
       "       nit: 24\n",
       "      njev: 38\n",
       "    status: 0\n",
       "   success: True\n",
       "         x: array([0.48288103, 0.61572027, 0.        ]),\n",
       "       fun: 60.99516089183949\n",
       "  hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "       jac: array([ 1.42108546e-06, -2.13162821e-06, -5.25140817e-02])\n",
       "   message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "      nfev: 68\n",
       "       nit: 9\n",
       "      njev: 17\n",
       "    status: 0\n",
       "   success: True\n",
       "         x: array([0.53696035, 0.00894374, 1.        ]),\n",
       "       fun: 62.1861236321015\n",
       "  hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "       jac: array([ 5.94013727e-04, -2.84217071e-05, -1.04614699e+00])\n",
       "   message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "      nfev: 320\n",
       "       nit: 50\n",
       "      njev: 80\n",
       "    status: 0\n",
       "   success: True\n",
       "         x: array([1.89540747e-03, 2.00000000e+01, 1.00000000e+00])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id     alpha          beta     decay       -LLH\n",
      "0   sub-2038  0.006002  2.000000e+01  1.000000  61.424837\n",
      "1   sub-2039  0.830144  5.318483e-01  0.020987  34.352419\n",
      "2   sub-2026  0.009392  2.000000e+01  0.532974  58.096880\n",
      "3   sub-2027  0.127701  5.493601e-01  0.000000  47.877589\n",
      "4   sub-2033  1.000000  1.183154e-01  1.000000  59.950593\n",
      "5   sub-2025  0.002477  2.000000e+01  0.000000  50.730065\n",
      "6   sub-2031  0.000000  1.000000e-10  1.000000  60.996952\n",
      "7   sub-2030  0.000000  1.000000e-10  1.000000  58.224363\n",
      "8   sub-2024  0.463954  4.272929e-01  0.000000  43.060880\n",
      "9   sub-2034  0.001483  2.000000e+01  0.000000  53.163115\n",
      "10  sub-2021  0.935232  1.868886e-01  0.000000  54.493332\n",
      "11  sub-2037  1.000000  2.674687e-01  0.070692  49.838614\n",
      "12  sub-2023  0.482881  6.157203e-01  0.000000  34.813597\n",
      "13  sub-2022  0.536960  8.943738e-03  1.000000  60.995161\n",
      "14  sub-2036  0.001895  2.000000e+01  1.000000  62.186124\n"
     ]
    }
   ],
   "source": [
    "params = pd.DataFrame(params)\n",
    "params['id'] = [file[:-4] for file in files]\n",
    "params['alpha'] = [params['x'][y][0] for y in range(len(params))]\n",
    "params['beta'] = [params['x'][y][1] for y in range(len(params))]\n",
    "params['decay'] = [params['x'][y][2] for y in range(len(params))]\n",
    "params['-LLH'] = [params['fun'][y] for y in range(len(params))]\n",
    "params = params[['id', 'alpha', 'beta', 'decay', '-LLH']]\n",
    "print(params)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save parameters in text file\n",
    "params.to_csv(path_or_buf = '../../output/missing_single_alpha_with_decay_model_params.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
