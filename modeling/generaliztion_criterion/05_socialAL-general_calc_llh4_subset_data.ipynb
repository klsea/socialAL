{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SocialAL Models\n",
    "# Calc llh from general learning model for subset of data\n",
    "KLS 12.19.22\n",
    "Project info: https://osf.io/b48n2/\n",
    "\n",
    "Model modified from :\n",
    "Fareri, D. S., Chang, L. J., & Delgado, M. R. (2012). Effects of direct social experience on trust decisions and neural reward circuitry. Frontiers in Neuroscience, 6, 1â€“17. https://doi.org/10.3389/fnins.2012.00148"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run common_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run single_alpha_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull in parameters fit to Trustworthy/Untrustworthy conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = pd.read_csv('../../output/generalization_criterion/a1_fit2_2cond_part.csv')\n",
    "pt.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('../../data/modeling')\n",
    "files.remove('.DS_Store')\n",
    "files.remove('missing')\n",
    "#print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_part = len(files)\n",
    "print('number of participants: ', n_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean(file):\n",
    "    path = os.path.join('../../data/modeling', file)\n",
    "    dt = pd.read_csv(path)\n",
    "    # recode trial type into numbers for model\n",
    "    def stims(trial_type):\n",
    "        if trial_type == \"Trustworthy\":\n",
    "            return 0\n",
    "        elif trial_type == \"Neutral\":\n",
    "            return 1\n",
    "        elif trial_type == \"Untrustworthy\":\n",
    "            return 2\n",
    "    dt['Stim_Sequence'] = dt['trial_type'].apply(stims)\n",
    "    # rename response_key to choice\n",
    "    def choices(response_key):\n",
    "        if response_key == 'None':\n",
    "            return 0 \n",
    "        else:\n",
    "            return response_key  \n",
    "    dt['Choice'] = dt['response_key'].apply(choices)\n",
    "    dt['Choice'] = pd.to_numeric(dt['Choice'])\n",
    "    # calculte the trustee response\n",
    "    def resp(trial_earnings):\n",
    "        if trial_earnings >= 12:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    dt['Trustee_Response'] = dt['trial_earnings'].apply(resp)\n",
    "    data = dt[['Stim_Sequence','Choice', 'Trustee_Response']]\n",
    "    # limit to neutral trials only\n",
    "    data = data[data['Stim_Sequence'] == 1]\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = load_and_clean(files[0])\n",
    "# data.head(20) # should only have 15 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create csv file\n",
    "file = open('../../output/generalization_criterion/a1_llh4_1cond_part.csv', 'w')\n",
    "\n",
    "# add header\n",
    "headerList = ['id','a1_llh']\n",
    "with open('../../output/generalization_criterion/a1_llh4_1cond_part.csv', 'a') as f_object: \n",
    "    dw = csv.DictWriter(f_object, delimiter = ',', fieldnames = headerList)\n",
    "    dw.writeheader()\n",
    "\n",
    "#loop thru participants\n",
    "for x in range(n_part):\n",
    "    print('loop:', x)\n",
    "    subject = files[x][:-4]\n",
    "    print(subject)\n",
    "    \n",
    "    # load and clean data\n",
    "    print('loading data')\n",
    "    data = load_and_clean(files[x])\n",
    "    \n",
    "    # pull parameters\n",
    "    print('pull parameters')\n",
    "    params = pt.loc[pt['id'] == subject].values.flatten().tolist()\n",
    "    #print(params[1:4])\n",
    "    \n",
    "    # calculting llh\n",
    "    print('calculating llh')\n",
    "    llh = get_likelihood_action(params[1:4], data)\n",
    "    a2 = [subject, llh]\n",
    "    print(a2)\n",
    "    \n",
    "    # save results\n",
    "    print('saving results')\n",
    "    with open('../../output/generalization_criterion/a1_llh4_1cond_part.csv', 'a') as f_object: # create a file object\n",
    "        writer_object = csv.writer(f_object) # pass the file object to csv writer\n",
    "        writer_object.writerow(a2) #pass list as argument to writerow\n",
    "        f_object.close() # close the file object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
