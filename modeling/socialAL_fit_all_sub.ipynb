{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SocialAL Model\n",
    "# Fit model to data - multiple subjects\n",
    "KLS 9.19.19  \n",
    "Project info: https://osf.io/b48n2/\n",
    "\n",
    "Model modified from :\n",
    "Fareri, D. S., Chang, L. J., & Delgado, M. R. (2012). Effects of direct social experience on trust decisions and neural reward circuitry. Frontiers in Neuroscience, 6, 1â€“17. https://doi.org/10.3389/fnins.2012.00148"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.3 (default, Mar 27 2019, 16:54:48) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_value(Prob, EV, choice, response):\n",
    "    invest = [0,3,6,9]\n",
    "    retain = [9-x for x in invest] #print (\"Retain list is: \", retain)\n",
    "    shared = [2*x for x in invest] #print (\"Shared list is: \", shared)\n",
    "    EV[choice-1] = retain[choice-1] + Prob*shared[choice-1]\n",
    "    return EV\n",
    "\n",
    "def update_prob(recip, Prob, a_gain, a_loss):\n",
    "    gain = max(recip - Prob, 0)\n",
    "    loss = min(recip - Prob, 0)\n",
    "    Prob = Prob + a_gain * gain + a_loss * loss\n",
    "    return Prob\n",
    "\n",
    "def get_action_selection_prob(beta, EV, choice):\n",
    "    numerator = np.exp(beta*EV[choice-1])\n",
    "    denominator = np.sum([np.exp(beta*x) for x in EV])\n",
    "    actionProb = numerator/denominator\n",
    "    return actionProb\n",
    "\n",
    "def get_action_selection_probs(beta, EV):\n",
    "    actionProbs = [get_action_selection_prob(beta, EV, x) for x in range(1,5)]\n",
    "    return actionProbs\n",
    "\n",
    "def get_likelihood_action(params, data):\n",
    "    a_gain = params[0]\n",
    "    a_loss = params[1]\n",
    "    beta = params[2]\n",
    "    \n",
    "    # initialize variables\n",
    "    prob = [0.5, 0.5, 0.5]\n",
    "    ev = [[9,9,9,9],[9,9,9,9],[9,9,9,9]]\n",
    "    \n",
    "    totalLLH = math.inf  \n",
    "    for trial in range(0, len(data)):\n",
    "        trustee = data['Stim_Sequence'][trial] # get trustee type\n",
    "        choice = data['Choice'][trial] # get choice made by participant\n",
    "        response = data['Trustee_Response'][trial] # get response from trustee\n",
    "        \n",
    "        # compute the probability of selecting each option for that trustee\n",
    "        probs = get_action_selection_probs(beta, ev[trustee])\n",
    "        \n",
    "        # use the probability of the selection (choice-probability) to update log likelihood\n",
    "        cprob = probs[choice-1]\n",
    "        \n",
    "        #add to cumulative log likelihood\n",
    "        totalLLH += -math.log(cprob)\n",
    "        \n",
    "        # update prob and value\n",
    "        prob[trustee] = update_prob(response, prob[trustee], a_gain, a_loss)\n",
    "        ev[trustee] = update_value(prob[trustee], ev[trustee], choice, response)\n",
    "        \n",
    "    return totalLLH\n",
    "\n",
    "def model_fit(data):\n",
    "    \n",
    "    # initialize free parameters with randomly chosen numbers\n",
    "    a_gain=random.uniform(0, 1)\n",
    "    a_loss=random.uniform(0, 1)\n",
    "    beta=random.uniform(0, 1)\n",
    "    params = [a_gain, a_loss, beta]\n",
    "    \n",
    "    # trying different solvers in the minimize call...\n",
    "    #results = minimize(get_likelihood_action, params, args =(data), method='Nelder-Mead', options = {'maxiter': 10000, 'disp': False})\n",
    "    results = minimize(get_likelihood_action, params, args =(data), method='BFGS', options = {'maxiter': 10000, 'disp': False})\n",
    "    return results.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('../data/modeling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean(file):\n",
    "    path = os.path.join('../data/modeling', file)\n",
    "    dt = pd.read_csv(path)\n",
    "    # recode trial type into numbers for model\n",
    "    def stims(trial_type):\n",
    "        if trial_type == \"Trustworthy\":\n",
    "            return 0\n",
    "        elif trial_type == \"Neutral\":\n",
    "            return 1\n",
    "        elif trial_type == \"Untrustworthy\":\n",
    "            return 2\n",
    "    dt['Stim_Sequence'] = dt['trial_type'].apply(stims)\n",
    "    # rename response_key to choice\n",
    "    def choices(response_key):\n",
    "        if response_key == 'None':\n",
    "            return 0 \n",
    "        else:\n",
    "            return response_key  \n",
    "    dt['Choice'] = dt['response_key'].apply(choices)\n",
    "    dt['Choice'] = pd.to_numeric(dt['Choice'])\n",
    "    # calculte the trustee response\n",
    "    def resp(trial_earnings):\n",
    "        if trial_earnings >= 12:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    dt['Trustee_Response'] = dt['trial_earnings'].apply(resp)\n",
    "    data = dt[['Stim_Sequence','Choice', 'Trustee_Response']]\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [model_fit(load_and_clean(file)) for file in files]\n",
    "params = pd.DataFrame(params)\n",
    "params\n",
    "params['id'] = [file[:-4] for file in files]\n",
    "params = params.rename({0:'alpha_gain', 1:'alpha_loss', 2:'beta', 'id':'id'}, axis='columns') # rename columns\n",
    "# reorder cols\n",
    "cols = params.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "params = params[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save parameters in text file\n",
    "params.to_csv(path_or_buf = '../output/model_params.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
