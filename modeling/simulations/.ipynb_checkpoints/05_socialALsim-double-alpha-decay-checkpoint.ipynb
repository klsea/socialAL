{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SocialAL Models\n",
    "# Data simulation and parameter recovery - multiple subjects\n",
    "KLS 8.30.19; update 7.7.22  \n",
    "Project info: https://osf.io/b48n2/\n",
    "\n",
    "Model modified from :\n",
    "Fareri, D. S., Chang, L. J., & Delgado, M. R. (2012). Effects of direct social experience on trust decisions and neural reward circuitry. Frontiers in Neuroscience, 6, 1â€“17. https://doi.org/10.3389/fnins.2012.00148"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.3 (default, Mar 27 2019, 16:54:48) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import beta\n",
    "from scipy.stats import gamma\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run common_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run double_alpha_decay_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_response(prob):     \n",
    "    n = random.uniform(0,1)\n",
    "    if n > prob:\n",
    "        response = 0\n",
    "    else:\n",
    "        response = 1\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "recip_rates = {0: 0.93, 1:0.6, 2:0.07}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New function to simulate data for one sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_data(tn, params):\n",
    "    # tn: number of trials desired\n",
    "    # params: ground truth of parameters\n",
    "    a_gain = params[0]\n",
    "    a_loss = params[1]\n",
    "    beta = params[2]\n",
    "    decay = params[3]\n",
    "    \n",
    "    # initialize variables\n",
    "    Probs = [0.5, 0.5, 0.5]\n",
    "    EVs = [[9,9,9,9],[9,9,9,9],[9,9,9,9]]\n",
    "    \n",
    "    # generate trial sequence\n",
    "    trial_sequence = np.repeat([0,1,2], tn)\n",
    "    random.shuffle(trial_sequence) #print(trial_sequence)\n",
    "    \n",
    "    trial = []\n",
    "    choices = []\n",
    "    responses = []\n",
    "    \n",
    "    for x in range(0,len(trial_sequence)):\n",
    "        t = trial_sequence[x] \n",
    "        \n",
    "        # Trial\n",
    "        trial.append(x+1)\n",
    "        \n",
    "        # Make a choice\n",
    "        choice = action_selection(get_action_selection_probs(beta, EVs[t]))\n",
    "        choices.append(choice) \n",
    "    \n",
    "        # Get a response\n",
    "        recip_rate = recip_rates.get(t) \n",
    "        \n",
    "        response = select_response(recip_rate) \n",
    "        responses.append(response)\n",
    "    \n",
    "        # after choice, update probability\n",
    "        if choice != 1:\n",
    "            Probs[t] = update_prob(response, Probs[t], a_gain, a_loss) \n",
    "        # then update value\n",
    "        EVs[t] = update_value(Probs[t]) \n",
    "        \n",
    "        # decay prob and value for other possible trustees \n",
    "        options = [0, 1, 2]\n",
    "        if choice == 2 or choice == 3 or choice == 4:\n",
    "            options.pop(t)\n",
    "        for x in options:\n",
    "            Probs[x] = Probs[x] + decay * (0.5 - Probs[x])\n",
    "            EVs[x] =  update_value(Probs[x]) \n",
    "\n",
    "    data = {'Trial': trial, 'Stim_Sequence': trial_sequence, 'Choice' : choices, 'Trustee_Response': responses}    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sim_data(15,[.2, .3, 2, .4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create set of parameters\n",
    "- distribution of alpha and beta parameters modeled following Cutler et al., 2021\n",
    "- distribution of decay parameters based on mean/SD reported for RL model in Collins & Frank, 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_gains = beta.rvs(a = 1.1, b = 1.1, size = 150)\n",
    "a_losses = beta.rvs(a = 1.1, b = 1.1, size = 150)\n",
    "betas = gamma.rvs(a = 1.2, scale = 5, size = 150)\n",
    "decays = norm.rvs(loc = 0.096, scale = 0.21, size = 150)\n",
    "decays[decays<0] = 0\n",
    "decays[decays>1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns= ['Trial','Stim_Sequence', 'Choice', 'Trustee_Response', 'Subject', 'Alpha_gain', 'Alpha_loss','Beta', 'Decay'])\n",
    "for p in range(len(betas)):\n",
    "    dt = sim_data(15, [a_gains[p], a_losses[p], betas[p], decays[p]])\n",
    "    dt['Subject'] = [p + 1] * 45\n",
    "    dt['Alpha_gain'] = [a_gains[p]] * 45\n",
    "    dt['Alpha_loss'] = [a_losses[p]] * 45\n",
    "    dt['Beta'] = [betas[p]] * 45\n",
    "    dt['Decay'] = [decays[p]] * 45\n",
    "    dt = pd.DataFrame(dt)\n",
    "    data = pd.concat([data, dt])\n",
    "data\n",
    "\n",
    "data.to_csv(path_or_buf = '../../output/simulation/sim_2alpha_decay_model_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New function to fit model to multiple subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit_mult_subject(data):\n",
    "    pdt = pd.DataFrame(columns = ['Subject', 'a_gain', 'a_loss', 'beta', 'decay'])\n",
    "    a = pd.unique(data['Subject'])\n",
    "    print('Number of Subs: ', len(a))\n",
    "    for sub in range(1,len(a)+1):\n",
    "        print('Subject: ', sub)\n",
    "        df = data[data['Subject']==sub]\n",
    "        dt = df.to_dict()\n",
    "        params = model_fit(dt)\n",
    "        line = {'Subject': sub, 'a_gain': params[0], 'a_loss': params[1], 'beta':params[2], 'decay':params[3]}\n",
    "        pdt = pdt.append(line, ignore_index=True)   \n",
    "    return(pdt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Subs:  150\n",
      "Subject:  1\n",
      "Subject:  2\n",
      "Subject:  3\n",
      "Subject:  4\n",
      "Subject:  5\n",
      "Subject:  6\n",
      "Subject:  7\n",
      "Subject:  8\n",
      "Subject:  9\n",
      "Subject:  10\n",
      "Subject:  11\n",
      "Subject:  12\n",
      "Subject:  13\n",
      "Subject:  14\n",
      "Subject:  15\n",
      "Subject:  16\n",
      "Subject:  17\n",
      "Subject:  18\n",
      "Subject:  19\n",
      "Subject:  20\n",
      "Subject:  21\n",
      "Subject:  22\n",
      "Subject:  23\n",
      "Subject:  24\n",
      "Subject:  25\n",
      "Subject:  26\n",
      "Subject:  27\n",
      "Subject:  28\n",
      "Subject:  29\n",
      "Subject:  30\n",
      "Subject:  31\n",
      "Subject:  32\n",
      "Subject:  33\n",
      "Subject:  34\n",
      "Subject:  35\n",
      "Subject:  36\n",
      "Subject:  37\n",
      "Subject:  38\n",
      "Subject:  39\n",
      "Subject:  40\n",
      "Subject:  41\n",
      "Subject:  42\n",
      "Subject:  43\n",
      "Subject:  44\n",
      "Subject:  45\n",
      "Subject:  46\n",
      "Subject:  47\n",
      "Subject:  48\n",
      "Subject:  49\n",
      "Subject:  50\n",
      "Subject:  51\n",
      "Subject:  52\n",
      "Subject:  53\n",
      "Subject:  54\n",
      "Subject:  55\n",
      "Subject:  56\n",
      "Subject:  57\n",
      "Subject:  58\n",
      "Subject:  59\n",
      "Subject:  60\n",
      "Subject:  61\n",
      "Subject:  62\n",
      "Subject:  63\n",
      "Subject:  64\n",
      "Subject:  65\n",
      "Subject:  66\n",
      "Subject:  67\n",
      "Subject:  68\n",
      "Subject:  69\n",
      "Subject:  70\n",
      "Subject:  71\n",
      "Subject:  72\n",
      "Subject:  73\n",
      "Subject:  74\n",
      "Subject:  75\n",
      "Subject:  76\n",
      "Subject:  77\n",
      "Subject:  78\n",
      "Subject:  79\n",
      "Subject:  80\n",
      "Subject:  81\n",
      "Subject:  82\n",
      "Subject:  83\n",
      "Subject:  84\n",
      "Subject:  85\n",
      "Subject:  86\n",
      "Subject:  87\n",
      "Subject:  88\n",
      "Subject:  89\n",
      "Subject:  90\n",
      "Subject:  91\n",
      "Subject:  92\n",
      "Subject:  93\n",
      "Subject:  94\n",
      "Subject:  95\n",
      "Subject:  96\n",
      "Subject:  97\n",
      "Subject:  98\n",
      "Subject:  99\n",
      "Subject:  100\n",
      "Subject:  101\n",
      "Subject:  102\n",
      "Subject:  103\n",
      "Subject:  104\n",
      "Subject:  105\n",
      "Subject:  106\n",
      "Subject:  107\n",
      "Subject:  108\n",
      "Subject:  109\n",
      "Subject:  110\n",
      "Subject:  111\n",
      "Subject:  112\n",
      "Subject:  113\n",
      "Subject:  114\n",
      "Subject:  115\n",
      "Subject:  116\n",
      "Subject:  117\n",
      "Subject:  118\n",
      "Subject:  119\n",
      "Subject:  120\n",
      "Subject:  121\n",
      "Subject:  122\n",
      "Subject:  123\n",
      "Subject:  124\n",
      "Subject:  125\n",
      "Subject:  126\n",
      "Subject:  127\n",
      "Subject:  128\n",
      "Subject:  129\n",
      "Subject:  130\n",
      "Subject:  131\n",
      "Subject:  132\n",
      "Subject:  133\n",
      "Subject:  134\n",
      "Subject:  135\n",
      "Subject:  136\n",
      "Subject:  137\n",
      "Subject:  138\n",
      "Subject:  139\n",
      "Subject:  140\n",
      "Subject:  141\n",
      "Subject:  142\n",
      "Subject:  143\n",
      "Subject:  144\n",
      "Subject:  145\n",
      "Subject:  146\n",
      "Subject:  147\n",
      "Subject:  148\n",
      "Subject:  149\n",
      "Subject:  150\n"
     ]
    }
   ],
   "source": [
    "precover = model_fit_mult_subject(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Subject    a_gain    a_loss          beta     decay\n",
      "0        1.0  0.026580  1.000000  9.057011e+00  0.029082\n",
      "1        2.0  1.000000  0.704440  4.659523e-01  0.021960\n",
      "2        3.0  0.000000  0.014621  2.000000e+01  0.000000\n",
      "3        4.0  1.000000  1.000000  8.079008e+00  0.000000\n",
      "4        5.0  0.009594  1.000000  2.000000e+01  0.000000\n",
      "5        6.0  1.000000  1.000000  1.172656e+01  0.000000\n",
      "6        7.0  1.000000  1.000000  7.147595e+00  1.000000\n",
      "7        8.0  0.191831  1.000000  2.000000e+01  0.810946\n",
      "8        9.0  1.000000  0.890321  1.206868e+01  0.000000\n",
      "9       10.0  0.634812  0.000000  1.000000e-10  1.000000\n",
      "10      11.0  0.759376  1.000000  1.264848e+01  0.000000\n",
      "11      12.0  1.000000  0.012081  1.157751e+01  0.000000\n",
      "12      13.0  1.000000  0.003660  2.000000e+01  0.000000\n",
      "13      14.0  1.000000  0.581016  1.607991e+01  0.000000\n",
      "14      15.0  1.000000  1.000000  9.024214e+00  0.000000\n",
      "15      16.0  1.000000  1.000000  9.403864e+00  0.000000\n",
      "16      17.0  0.000000  0.464435  1.000000e-10  0.985519\n",
      "17      18.0  1.000000  1.000000  1.015157e+01  0.000000\n",
      "18      19.0  1.000000  1.000000  2.000000e+01  0.000000\n",
      "19      20.0  1.000000  1.000000  2.000000e+01  0.808725\n",
      "20      21.0  0.050709  0.000000  2.000000e+01  0.295313\n",
      "21      22.0  0.155518  1.000000  1.991838e+01  0.000000\n",
      "22      23.0  1.000000  1.000000  1.195125e+01  0.000000\n",
      "23      24.0  1.000000  0.746856  1.398480e+01  0.000000\n",
      "24      25.0  1.000000  1.000000  2.000000e+01  0.993164\n",
      "25      26.0  1.000000  1.000000  2.000000e+01  0.791641\n",
      "26      27.0  1.000000  1.000000  1.038931e+01  0.000000\n",
      "27      28.0  1.000000  1.000000  1.323213e+01  0.000000\n",
      "28      29.0  1.000000  1.000000  1.156910e+01  0.000000\n",
      "29      30.0  1.000000  1.000000  9.984314e+00  0.000000\n",
      "..       ...       ...       ...           ...       ...\n",
      "120    121.0  1.000000  0.094306  2.000000e+01  0.716956\n",
      "121    122.0  1.000000  0.503496  2.000000e+01  0.902184\n",
      "122    123.0  0.350136  1.000000  1.957300e+01  0.000000\n",
      "123    124.0  0.018302  0.006876  2.000000e+01  0.000000\n",
      "124    125.0  1.000000  1.000000  2.000000e+01  0.000000\n",
      "125    126.0  0.115809  1.000000  2.000000e+01  0.746813\n",
      "126    127.0  1.000000  1.000000  1.426036e+01  0.000000\n",
      "127    128.0  1.000000  1.000000  8.314188e+00  0.000000\n",
      "128    129.0  0.914559  1.000000  1.016648e+01  0.000000\n",
      "129    130.0  1.000000  0.890469  7.543639e+00  0.625359\n",
      "130    131.0  0.814066  0.214813  7.587760e+00  1.000000\n",
      "131    132.0  1.000000  1.000000  1.232183e+01  0.000000\n",
      "132    133.0  1.000000  0.893333  2.000000e+01  0.000000\n",
      "133    134.0  0.076980  1.000000  1.356356e+01  0.000000\n",
      "134    135.0  0.008240  0.010973  2.000000e+01  0.000000\n",
      "135    136.0  1.000000  0.321638  1.992578e+01  0.000000\n",
      "136    137.0  1.000000  0.047506  2.000000e+01  0.790107\n",
      "137    138.0  1.000000  1.000000  8.660376e+00  0.000000\n",
      "138    139.0  0.018167  1.000000  7.699266e+00  0.000000\n",
      "139    140.0  1.000000  1.000000  1.708453e+01  0.000000\n",
      "140    141.0  1.000000  0.255034  1.062503e+00  0.597044\n",
      "141    142.0  1.000000  1.000000  1.030767e+01  0.000000\n",
      "142    143.0  0.902423  1.000000  1.610482e+01  0.000000\n",
      "143    144.0  1.000000  0.397107  2.000000e+01  0.554156\n",
      "144    145.0  1.000000  1.000000  1.324823e+01  0.000000\n",
      "145    146.0  1.000000  1.000000  1.260420e+01  0.000000\n",
      "146    147.0  0.078282  1.000000  2.000000e+01  0.552959\n",
      "147    148.0  0.800470  1.000000  1.016345e+00  0.133917\n",
      "148    149.0  1.000000  1.000000  1.744881e+01  0.000000\n",
      "149    150.0  1.000000  0.892073  1.331263e+01  0.000000\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(precover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "precover.to_csv(path_or_buf = '../../output/simulation/sim_2alpha_decay_model_fit.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
