{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SocialAL Models\n",
    "# Data simulation using best-fit parameters - multiple subjects\n",
    "KLS 8.30.19; update 7.7.22; update 10.31.22  \n",
    "Project info: https://osf.io/b48n2/\n",
    "\n",
    "Model modified from :\n",
    "Fareri, D. S., Chang, L. J., & Delgado, M. R. (2012). Effects of direct social experience on trust decisions and neural reward circuitry. Frontiers in Neuroscience, 6, 1â€“17. https://doi.org/10.3389/fnins.2012.00148"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.0 (v3.11.0:deaf509e8f, Oct 24 2022, 14:43:23) [Clang 13.0.0 (clang-1300.0.29.30)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import beta\n",
    "from scipy.stats import gamma\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run ../common_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run ../baseline_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_response(prob):     \n",
    "    n = random.uniform(0,1)\n",
    "    if n > prob:\n",
    "        response = 0\n",
    "    else:\n",
    "        response = 1\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "recip_rates = {0: 0.93, 1:0.6, 2:0.07}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New function to simulate data for one sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_data(tn, params):\n",
    "    # tn: number of trials desired\n",
    "    # params: ground truth of parameters\n",
    "    \n",
    "    beta = params\n",
    "    \n",
    "    # initialize variables\n",
    "    Probs = [0.5, 0.5, 0.5]\n",
    "    EVs = [[9,9,9,9],[9,9,9,9],[9,9,9,9]]\n",
    "    \n",
    "    # generate trial sequence\n",
    "    trial_sequence = np.repeat([0,1,2], tn)\n",
    "    random.shuffle(trial_sequence) #print(trial_sequence)\n",
    "    \n",
    "    trial = []\n",
    "    choices = []\n",
    "    responses = []\n",
    "    \n",
    "    for x in range(0,len(trial_sequence)):\n",
    "        t = trial_sequence[x] \n",
    "        \n",
    "        # Trial\n",
    "        trial.append(x+1)\n",
    "        \n",
    "        # Make a choice\n",
    "        choice = action_selection(get_action_selection_probs(beta, EVs[t]))\n",
    "        choices.append(choice) \n",
    "    \n",
    "        # Get a response\n",
    "        recip_rate = recip_rates.get(t) \n",
    "        \n",
    "        response = select_response(recip_rate) \n",
    "        responses.append(response)\n",
    "    \n",
    "        # then update value\n",
    "        EVs[t] = update_value(Probs[t]) \n",
    "\n",
    "    data = {'Trial': trial, 'Stim_Sequence': np.ndarray.tolist(trial_sequence), 'Choice' : choices, 'Trustee_Response': responses, 'Beta': [beta] * tn *3 }    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sim_data(15,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull in best-fit parameters from participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id      beta      X.LLH\n",
      "0   sub-2013  0.113988  60.996952\n",
      "1   sub-2007  0.816956  58.224363\n",
      "2   sub-2006  0.671496  60.996952\n",
      "3   sub-2012  0.088588  62.383246\n",
      "4   sub-2004  0.333262  62.383246\n",
      "..       ...       ...        ...\n",
      "58  sub-2009  0.129989  62.383246\n",
      "59  sub-2037  0.623544  58.224363\n",
      "60  sub-2023  0.150704  60.996952\n",
      "61  sub-2022  0.184520  60.996952\n",
      "62  sub-2036  0.171241  62.383246\n",
      "\n",
      "[63 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "dt = pd.read_csv('../../../output/baseline_model_params.csv')\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = open('../../../output/socialAL_cut.csv', 'r')\n",
    "#dt2 = list(csv.reader(file))\n",
    "#file.close()\n",
    "#cut = [item for sublist in dt2 for item in sublist]\n",
    "#dt = dt1[~dt1['id'].isin(cut)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.113988\n",
      "1     0.816956\n",
      "2     0.671496\n",
      "3     0.088588\n",
      "4     0.333262\n",
      "        ...   \n",
      "58    0.129989\n",
      "59    0.623544\n",
      "60    0.150704\n",
      "61    0.184520\n",
      "62    0.171241\n",
      "Name: beta, Length: 63, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "betas = dt['beta']\n",
    "parent_sub = dt['id']\n",
    "print(betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns= ['Trial', 'Stim_Sequence', 'Choice', 'Trustee_Response', 'Beta', 'Subject'])\n",
    "for p in range(len(betas)):\n",
    "    for q in range(1,11):\n",
    "        dt = sim_data(15, betas[p])\n",
    "        dt['Subject'] = parent_sub[p] + '_' + str(q) #[p + 1] * 45\n",
    "        dt = pd.DataFrame(dt)\n",
    "        data = pd.concat([data, dt])\n",
    "    \n",
    "data.to_csv(path_or_buf = '../../../output/simulation/part_params/sim_baseline_model_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = data[data['Subject']==120]\n",
    "# df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
